"""
This type stub file was generated by pyright.
"""

import torch
from typing import List
from torch import Tensor

"""
This type stub file was generated by pyright.
"""
class FloatFunctional(torch.nn.Module):
    r"""State collector class for float operations.

    The instance of this class can be used instead of the ``torch.`` prefix for
    some operations. See example usage below.

    .. note::

        This class does not provide a ``forward`` hook. Instead, you must use
        one of the underlying functions (e.g. ``add``).

    Examples::

        >>> f_add = FloatFunctional()
        >>> a = torch.tensor(3.0)
        >>> b = torch.tensor(4.0)
        >>> f_add.add(a, b)  # Equivalent to ``torch.add(a, b)``

    Valid operation names:
        - add
        - cat
        - mul
        - add_relu
        - add_scalar
        - mul_scalar
    """
    def __init__(self) -> None:
        ...
    
    def forward(self, x):
        ...
    
    def add(self, x: Tensor, y: Tensor) -> Tensor:
        ...
    
    def add_scalar(self, x: Tensor, y: float) -> Tensor:
        ...
    
    def mul(self, x: Tensor, y: Tensor) -> Tensor:
        ...
    
    def mul_scalar(self, x: Tensor, y: float) -> Tensor:
        ...
    
    def cat(self, x: List[Tensor], dim: int = ...) -> Tensor:
        ...
    
    def add_relu(self, x: Tensor, y: Tensor) -> Tensor:
        ...
    


class QFunctional(torch.nn.Module):
    r"""Wrapper class for quantized operations.

    The instance of this class can be used instead of the
    ``torch.ops.quantized`` prefix. See example usage below.

    .. note::

        This class does not provide a ``forward`` hook. Instead, you must use
        one of the underlying functions (e.g. ``add``).

    Examples::

        >>> q_add = QFunctional()
        >>> a = torch.quantize_per_tensor(torch.tensor(3.0), 1.0, 0, torch.qint32)
        >>> b = torch.quantize_per_tensor(torch.tensor(4.0), 1.0, 0, torch.qint32)
        >>> q_add.add(a, b)  # Equivalent to ``torch.ops.quantized.add(a, b, 1.0, 0)``

    Valid operation names:
        - add
        - cat
        - mul
        - add_relu
        - add_scalar
        - mul_scalar
    """
    def __init__(self) -> None:
        ...
    
    def extra_repr(self):
        ...
    
    def forward(self, x):
        ...
    
    def add(self, x: Tensor, y: Tensor) -> Tensor:
        ...
    
    def add_scalar(self, x: Tensor, y: float) -> Tensor:
        ...
    
    def mul(self, x: Tensor, y: Tensor) -> Tensor:
        ...
    
    def mul_scalar(self, x: Tensor, y: float) -> Tensor:
        ...
    
    def cat(self, x: List[Tensor], dim: int = ...) -> Tensor:
        ...
    
    def add_relu(self, x: Tensor, y: Tensor) -> Tensor:
        ...
    
    @classmethod
    def from_float(cls, mod):
        ...
    


