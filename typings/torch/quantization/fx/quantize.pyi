"""
This type stub file was generated by pyright.
"""

import torch
from .quantization_patterns import *

def get_new_attr_name_with_prefix(prefix):
    ...

def collect_producer_nodes(node):
    r''' Starting from a target node, trace back until we hit inpu or
    getattr node. This is used to extract the chain of operators
    starting from getattr to the target node, for example
    def forward(self, x):
      observed = self.observer(self.weight)
      return F.linear(x, observed)
    collect_producer_nodes(observed) will either return a list of nodes that produces
    the observed node or None if we can't extract a self contained graph without
    free variables(inputs of the forward function).
    '''
    ...

def graph_module_from_producer_nodes(root, producer_nodes):
    r''' Construct a graph module from extracted producer nodes
    from `collect_producer_nodes` function
    Args:
      root: the root module for the original graph
      producer_nodes: a list of nodes we use to construct the graph
    Return:
      A graph module constructed from the producer nodes
    '''
    ...

def assert_and_get_unique_device(module):
    """
    Returns the unique device for a module, or None if no device is found.
    Throws an error if multiple devices are detected.
    """
    ...

def is_activation_post_process(module):
    ...

def is_submodule_of_fake_quant(name, module, named_modules):
    ...

def get_flattened_qconfig_dict(qconfig_dict):
    """ flatten the global, object_type and module_name qconfig
    to the same qconfig_dict so that it can be used by
    propagate_qconfig_ function.
    "module_name_regex" is ignored for now since it's not supported
    in propagate_qconfig_, but it can be fixed later.

    For example:
    Input: {
      "": qconfig,
      "object_type": [
        (torch.add, qconfig)
      ],
      "module_name": [
        ("conv", qconfig)
      ]
    }

    Output: {
      "": qconfig,
      torch.add: qconfig,
      "conv": qconfig
    }
    """
    ...

def convert_dict_to_ordered_dict(qconfig_dict):
    """ Convert dict in qconfig_dict to ordered dict
    """
    ...

WEIGHT_INDEX_DICT = { torch.nn.functional.conv2d: [1],torch.nn.functional.linear: [1] }
WEIGHT_PREPACK_OPS = torch._ops.ops.quantized.linear_prepack, torch._ops.ops.quantized.linear_prepack_fp16, torch._ops.ops.quantized.conv2d_prepack
class Quantizer:
    def __init__(self) -> None:
        ...
    
    def save_state(self, observed):
        ...
    
    def restore_state(self, observed):
        ...
    
    def prepare(self, model, qconfig_dict, inplace=...):
        ...
    
    def prepare_dynamic(self, model, qconfig_dict, inplace=...):
        ...
    
    def convert(self, model, inplace=..., debug=..., is_dynamic=...):
        ...
    


